{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5b1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "classList = ['dry', 'healthy', 'sick','Good Morning']\n",
    "hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                                 min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "sequenceLength = 30\n",
    "\n",
    "def normalizeCoordinates(coords):\n",
    "    \n",
    "    baseX = 0\n",
    "    baseY = 0\n",
    "\n",
    "    for i, val in enumerate(coords):\n",
    "        if i == 0:\n",
    "            baseX = val[0]\n",
    "            baseY = val[1]\n",
    "\n",
    "        coords[i][0] = coords[i][0] - baseX\n",
    "        coords[i][1] = coords[i][1] - baseY \n",
    "\n",
    "    coords = list(itertools.chain.from_iterable(coords))\n",
    "\n",
    "    maxVal = max(list(map(abs, coords)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / maxVal\n",
    "\n",
    "    coords = list(map(normalize_, coords))\n",
    "\n",
    "    return coords\n",
    "\n",
    "def skeletonExtraction(path):\n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if(success == False):\n",
    "\n",
    "       \n",
    "            cap.release()\n",
    "            break\n",
    "        \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "        \n",
    "        hLeft = None\n",
    "        hRight = None\n",
    "\n",
    "        if(results.multi_hand_landmarks):\n",
    "            for idx, handLms in enumerate(results.multi_hand_landmarks):\n",
    "                \n",
    "                hand = []\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x *w), int(lm.y*h)\n",
    "                    hand.append([cx, cy])\n",
    "\n",
    "                label = results.multi_handedness[idx].classification[0].label\n",
    "                \n",
    "\n",
    "                if(label == 'Left'):\n",
    "                    hLeft = normalizeCoordinates(hand)\n",
    "                elif(label == 'Right'):\n",
    "                    hRight = normalizeCoordinates(hand)\n",
    "        \n",
    "        if(hLeft != None):\n",
    "            left.append(hLeft)\n",
    "        if(hRight != None):\n",
    "            right.append(hRight)\n",
    "    \n",
    "    countLeft = len(left)\n",
    "    countRight = len(right)\n",
    "    windowLeft = max(countLeft/sequenceLength, 1)\n",
    "    windowRight = max(countRight/sequenceLength, 1)\n",
    "\n",
    "    finalFeatures = []\n",
    "\n",
    "    if countLeft < sequenceLength or countRight < sequenceLength:\n",
    "        return []\n",
    "\n",
    "\n",
    "    for i in range(0, sequenceLength):\n",
    "        \n",
    "        finalFeatures.append(left[int(i * windowLeft)] + right[int(i * windowRight)])\n",
    "\n",
    "    return np.asarray(finalFeatures)\n",
    "\n",
    "def inputProcessing(path):\n",
    "    featuress = skeletonExtraction(path)\n",
    "    temp = [featuress]\n",
    "\n",
    "    return np.asarray(temp)\n",
    "\n",
    "def predict(fp):\n",
    "    jsonFile = open('my.json', 'r')\n",
    "    loadedModel = jsonFile.read()\n",
    "    loadedModel = keras.models.model_from_json(loadedModel)\n",
    "    loadedModel.load_weights('my.h5')\n",
    "    loadedModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    featuress = inputProcessing(fp)\n",
    "    outputs = loadedModel.predict(featuress)\n",
    "    labels = classList[np.argmax(outputs)]\n",
    "    return(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d72bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024BD94DF2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Good Morning\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"800x600\")\n",
    "root.configure(bg=\"yellow\")\n",
    "file_path=\"C:/Users/91790/Desktop/untitled-video-made-with-clipchamp_4sJmb4vZ.mp4\"\n",
    "#This function should call the Python program that records webcam video using OpenCV.\n",
    "def record_video():\n",
    "    os.system('C:/Users/91790/Desktop/record.py')\n",
    "    \n",
    "def choose_file():\n",
    "    file_path = filedialog.askopenfilename(initialdir=\"D:/isl_projects/datasets/\", title=\"Select a Video File\",\n",
    "                                           filetypes=((\"Video files\", \"*.MOV\"),\n",
    "                                                      (\"all files\", \"*.*\")))\n",
    "    display_video(file_path)\n",
    "    \n",
    "def display_video(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "    h, w, channels = frame.shape\n",
    "    scale_factor = 0.25  # Reduce the size by 4x\n",
    "    h = int(h * scale_factor)\n",
    "    w = int(w * scale_factor)\n",
    "    video_canvas.config(width=w, height=h)\n",
    "    video_canvas.pack()\n",
    "    while ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        img = Image.fromarray(frame)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        video_canvas.img_tk = img_tk\n",
    "        video_canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "        root.update()\n",
    "        ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "video_canvas = tk.Canvas(root)\n",
    "video_canvas.pack()\n",
    "\n",
    "button1 = tk.Button(root, text=\"Select Video\", command=choose_file)\n",
    "button1.pack()\n",
    "button2 = tk.Button(root, text=\"Record Video\", command=record_video)\n",
    "button2.pack(side=\"bottom\")\n",
    "btn = tk.Button(root, text=\"Click Me\", command=partial(predict(),file_path))\n",
    "btn.pack(side=\"bottom\")\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97384001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cdef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
