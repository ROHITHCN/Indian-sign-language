{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597f502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "from keras import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "# %%\n",
    "dataset = \"D:\\isl_projects\\datasets\"\n",
    "\n",
    "classList = ['dry', 'healthy', 'sick']\n",
    "print(len(classList))\n",
    "\n",
    "# %%\n",
    "hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                                 min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "sequenceLength = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60454834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3645c4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2305c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCoordinates(coords):\n",
    "\n",
    "    baseX = 0\n",
    "    baseY = 0\n",
    "\n",
    "    for i, val in enumerate(coords):\n",
    "        if i == 0:\n",
    "            baseX = val[0]\n",
    "            baseY = val[1]\n",
    "\n",
    "        coords[i][0] = coords[i][0] - baseX\n",
    "        coords[i][1] = coords[i][1] - baseY\n",
    "\n",
    "    coords = list(itertools.chain.from_iterable(coords))\n",
    "\n",
    "    maxVal = max(list(map(abs, coords)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / maxVal\n",
    "\n",
    "    coords = list(map(normalize_, coords))\n",
    "\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5a2c1be",
   "metadata": {},
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967c3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletonExtraction(path):\n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        #cv2.imshow('Mediapipe Feed', img)\n",
    "        #if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "         #   break\n",
    "        if (success == False):\n",
    "\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "\n",
    "        hLeft = None\n",
    "        hRight = None\n",
    "\n",
    "        if (results.multi_hand_landmarks):\n",
    "            for idx, handLms in enumerate(results.multi_hand_landmarks):\n",
    "\n",
    "                hand = []\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y*h)\n",
    "                    hand.append([cx, cy])\n",
    "\n",
    "                label = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "                if (label == 'Left'):\n",
    "                    hLeft = normalizeCoordinates(hand)\n",
    "                elif (label == 'Right'):\n",
    "                    hRight = normalizeCoordinates(hand)\n",
    "\n",
    "        if (hLeft != None):\n",
    "            left.append(hLeft)\n",
    "        if (hRight != None):\n",
    "            right.append(hRight)\n",
    "\n",
    "    countLeft = len(left)\n",
    "    countRight = len(right)\n",
    "    windowLeft = max(countLeft/sequenceLength, 1)\n",
    "    windowRight = max(countRight/sequenceLength, 1)\n",
    "\n",
    "    finalFeatures = []\n",
    "\n",
    "    if countLeft < sequenceLength or countRight < sequenceLength:\n",
    "        return []\n",
    "\n",
    "    for i in range(0, sequenceLength):\n",
    "\n",
    "        finalFeatures.append(\n",
    "            left[int(i * windowLeft)] + right[int(i * windowRight)])\n",
    "    #cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    return np.asarray(finalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0904b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "\n",
    "    for index, name in enumerate(classList):\n",
    "        filesList = os.listdir(os.path.join(dataset, name))\n",
    "\n",
    "        for i in filesList:\n",
    "\n",
    "            path = os.path.join(dataset, name, i)\n",
    "\n",
    "            extractedFeatures = skeletonExtraction(path)\n",
    "\n",
    "            if (len(extractedFeatures) == sequenceLength):\n",
    "                features.append(extractedFeatures)\n",
    "                labels.append(index)\n",
    "                paths.append(path)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3fe90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, paths = createDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ba7f34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encodedLabels \u001b[38;5;241m=\u001b[39m to_categorical(\u001b[43mlabels\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m      4\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      5\u001b[0m     features, encodedLabels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m69\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "encodedLabels = to_categorical(labels)\n",
    "\n",
    "# %%\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, encodedLabels, test_size=0.01, random_state=69)\n",
    "\n",
    "\n",
    "# %%\n",
    "x_train.shape\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(30, 84)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "model.fit(x=x_train, y=y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# %%\n",
    "modelEvaluate = model.evaluate(x_test, y_test)\n",
    "\n",
    "# %%\n",
    "model.save_weights(\"my.h5\")\n",
    "modelJSON = model.to_json()\n",
    "with open('my.json', 'w') as jsonFile:\n",
    "    jsonFile.write(modelJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48015731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputProcessing(path):\n",
    "    features = skeletonExtraction(path)\n",
    "    temp = [features]\n",
    "\n",
    "    return np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcbda42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m inputProcessing(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124misl_projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDry\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMVI_5167.MOV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(features)\n\u001b[0;32m      3\u001b[0m label \u001b[38;5;241m=\u001b[39m classList[np\u001b[38;5;241m.\u001b[39margmax(output)]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "features = inputProcessing(\"D:\\isl_projects\\datasets\\Dry\\MVI_5167.MOV\")\n",
    "output = model.predict(features)\n",
    "label = classList[np.argmax(output)]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edde832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFile = open('my.json', 'r')\n",
    "loadedModel = jsonFile.read()\n",
    "loadedModel = keras.models.model_from_json(loadedModel)\n",
    "loadedModel.load_weights('my.h5')\n",
    "loadedModel.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b673d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "features = inputProcessing(\"D:\\isl_projects\\datasets\\Dry\\MVI_9277.MOV\")\n",
    "output = loadedModel.predict(features)\n",
    "label = classList[np.argmax(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd97157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dry\n",
      "[[0.99167514 0.00453334 0.00379142]]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
