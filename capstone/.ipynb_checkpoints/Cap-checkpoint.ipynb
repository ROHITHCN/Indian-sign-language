{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed1d564",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, LSTM, Activation, BatchNormalization\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coordination_config_pb2\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      6\u001b[0m _b\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x:x) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m _message\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reflection \u001b[38;5;28;01mas\u001b[39;00m _reflection\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\google\\protobuf\\descriptor.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n\u001b[0;32m     42\u001b[0m _USE_C_DESCRIPTORS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_implementation\u001b[38;5;241m.\u001b[39mType() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     44\u001b[0m   \u001b[38;5;66;03m# Used by MakeDescriptor in cpp mode\u001b[39;00m\n",
      "File \u001b[1;32mD:\\softwares\\python310.5\\lib\\site-packages\\google\\protobuf\\internal\\api_implementation.py:40\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m   \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api_implementation\n\u001b[0;32m     41\u001b[0m   \u001b[38;5;66;03m# The compile-time constants in the _api_implementation module can be used to\u001b[39;00m\n\u001b[0;32m     42\u001b[0m   \u001b[38;5;66;03m# switch to a certain implementation of the Python API at build time.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m   _api_version \u001b[38;5;241m=\u001b[39m _api_implementation\u001b[38;5;241m.\u001b[39mapi_version\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "from keras import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fd8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = ['dry', 'healthy', 'sick','Good Morning']\n",
    "hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                                 min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "sequenceLength = 30\n",
    "filepath=r\"C:\\Users\\Jeya Samthosh Kumar\\Desktop\\Capstone\\cam_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a116de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCoordinates(coords):\n",
    "\n",
    "    baseX = 0\n",
    "    baseY = 0\n",
    "\n",
    "    for i, val in enumerate(coords):\n",
    "        if i == 0:\n",
    "            baseX = val[0]\n",
    "            baseY = val[1]\n",
    "\n",
    "        coords[i][0] = coords[i][0] - baseX\n",
    "        coords[i][1] = coords[i][1] - baseY\n",
    "\n",
    "    coords = list(itertools.chain.from_iterable(coords))\n",
    "\n",
    "    maxVal = max(list(map(abs, coords)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / maxVal\n",
    "\n",
    "    coords = list(map(normalize_, coords))\n",
    "\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a10b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletonExtraction(path):\n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if (success == False):\n",
    "\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "\n",
    "        hLeft = None\n",
    "        hRight = None\n",
    "\n",
    "        if (results.multi_hand_landmarks):\n",
    "            for idx, handLms in enumerate(results.multi_hand_landmarks):\n",
    "\n",
    "                hand = []\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y*h)\n",
    "                    hand.append([cx, cy])\n",
    "\n",
    "                label = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "                if (label == 'Left'):\n",
    "                    hLeft = normalizeCoordinates(hand)\n",
    "                elif (label == 'Right'):\n",
    "                    hRight = normalizeCoordinates(hand)\n",
    "\n",
    "        if (hLeft != None):\n",
    "            left.append(hLeft)\n",
    "        if (hRight != None):\n",
    "            right.append(hRight)\n",
    "\n",
    "    countLeft = len(left)\n",
    "    countRight = len(right)\n",
    "    windowLeft = max(countLeft/sequenceLength, 1)\n",
    "    windowRight = max(countRight/sequenceLength, 1)\n",
    "\n",
    "    finalFeatures = []\n",
    "\n",
    "    if countLeft < sequenceLength or countRight < sequenceLength:\n",
    "        return []\n",
    "\n",
    "    for i in range(0, sequenceLength):\n",
    "\n",
    "        finalFeatures.append(\n",
    "            left[int(i * windowLeft)] + right[int(i * windowRight)])\n",
    "\n",
    "    return np.asarray(finalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ec2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inputProcessing():\n",
    "    features = np.asarray([skeletonExtraction(filepath)])\n",
    "    jsonFile = open('my.json', 'r')\n",
    "    loadedModel = jsonFile.read()\n",
    "    loadedModel = keras.models.model_from_json(loadedModel)\n",
    "    loadedModel.load_weights('my.h5')\n",
    "    loadedModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    output = loadedModel.predict(features)\n",
    "    label = classList[np.argmax(output)]\n",
    "    button_pred.config(text=label)\n",
    "    print(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44f0b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13994c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\softwares\\python310.5\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\91790\\AppData\\Local\\Temp\\ipykernel_4212\\2961508784.py\", line 119, in choose_file\n",
      "    filepath = filedialog.askopenfilename(initialdir=\".\", title=\"Select a Video File\",\n",
      "  File \"D:\\softwares\\python310.5\\lib\\tkinter\\filedialog.py\", line 384, in askopenfilename\n",
      "    return Open(**options).show()\n",
      "  File \"D:\\softwares\\python310.5\\lib\\tkinter\\commondialog.py\", line 45, in show\n",
      "    s = master.tk.call(self.command, *master._options(self.options))\n",
      "_tkinter.TclError: bad Macintosh file type \"*.avi\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import time\n",
    "# from model import predict\n",
    "#os.chdir(\"/home/vivek/college/capstone/gui\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1920x1080\")\n",
    "# root.configure(bg=\"yellow\")\n",
    "file_path = ''\n",
    "\n",
    "frame = tk.Frame(height=480, width=640)\n",
    "\n",
    "frame.place(x=10, y=290)\n",
    "lmain = tk.Label(frame)\n",
    "lmain.place(x=0, y=0)\n",
    "\n",
    "filename = str(time.time())+'video.avi'\n",
    "frames_per_second = 30.0\n",
    "res = '480p'\n",
    "\n",
    "# Set resolution for the video capture\n",
    "# Function adapted from https://kirr.co/0l6qmh\n",
    "\n",
    "\n",
    "def change_res(cap, width, height):\n",
    "    cap.set(3, width)\n",
    "    cap.set(4, height)\n",
    "\n",
    "\n",
    "# Standard Video Dimensions Sizes\n",
    "STD_DIMENSIONS = {\n",
    "    \"480p\": (640, 480),\n",
    "    \"720p\": (1280, 720),\n",
    "    \"1080p\": (1920, 1080),\n",
    "    \"4k\": (3840, 2160),\n",
    "}\n",
    "\n",
    "\n",
    "# grab resolution dimensions and set video capture to it.\n",
    "def get_dims(cap, res='1080p'):\n",
    "    width, height = STD_DIMENSIONS[\"480p\"]\n",
    "    if res in STD_DIMENSIONS:\n",
    "        width, height = STD_DIMENSIONS[res]\n",
    "    # change the current caputre device\n",
    "    # to the resulting resolution\n",
    "    change_res(cap, width, height)\n",
    "    return width, height\n",
    "\n",
    "\n",
    "# Video Encoding, might require additional installs\n",
    "# Types of Codes: http://www.fourcc.org/codecs.php\n",
    "VIDEO_TYPE = {\n",
    "    'avi': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    # 'mp4': cv2.VideoWriter_fourcc(*'H264'),\n",
    "    'mp4': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "}\n",
    "\n",
    "\n",
    "def get_video_type(filename):\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    if ext in VIDEO_TYPE:\n",
    "        return VIDEO_TYPE[ext]\n",
    "    return VIDEO_TYPE['avi']\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# out = cv2.VideoWriter(str(time.time())+'video.avi',\n",
    "#                       cv2.VideoWriter_fourcc(*'XVID'), 25, get_dims(cap, res))\n",
    "recording = False\n",
    "\n",
    "# Define a function to start recording\n",
    "\n",
    "\n",
    "def start_recording():\n",
    "    global recording\n",
    "    recording = True\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    out = cv2.VideoWriter(str(time.time())+'video.avi',\n",
    "                          cv2.VideoWriter_fourcc(*'XVID'), 30, get_dims(cap, res))\n",
    "    button_start.config(text=\"Stop Recording\",\n",
    "                        command=lambda: stop_recording(cap, out))\n",
    "    record_video(cap, out)\n",
    "    # stop_recording\n",
    "# Define a function to stop recording\n",
    "\n",
    "\n",
    "def stop_recording(cap, out):\n",
    "    global recording\n",
    "    recording = False\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    button_start.config(text=\"Start Recording\", command=start_recording)\n",
    "\n",
    "# This function should call the Python program that records webcam video using OpenCV.\n",
    "\n",
    "\n",
    "def record_video(cap, out):\n",
    "    if recording:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            \n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = image\n",
    "            imgarr = Image.fromarray(img)\n",
    "            imgtk = ImageTk.PhotoImage(imgarr)\n",
    "            lmain.imgtk = imgtk\n",
    "            lmain.configure(image=imgtk)\n",
    "        out.write(frame)\n",
    "        lmain.after(10, lambda: record_video(cap, out))\n",
    "    # cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "def choose_file():\n",
    "    filepath = filedialog.askopenfilename(initialdir=\".\", title=\"Select a Video File\",\n",
    "                                           filetypes=((\"Video files\", \"*.mp4\"),\n",
    "                                                      (\"all files\", \"\")))\n",
    "    display_video(filepath)\n",
    "\n",
    "\n",
    "def display_video(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "    h, w, channels = frame.shape\n",
    "    scale_factor = 0.25  # Reduce the size by 4x\n",
    "    h = int(h * scale_factor)\n",
    "    w = int(w * scale_factor)\n",
    "    video_canvas.config(width=w, height=h)\n",
    "    video_canvas.pack()\n",
    "    while ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        img = Image.fromarray(frame)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        video_canvas.img_tk = img_tk\n",
    "        video_canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "        root.update()\n",
    "        ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "video_canvas = tk.Canvas(root)\n",
    "video_canvas.pack()\n",
    "\n",
    "button1 = tk.Button(root, text=\"Select Video\", command=choose_file)\n",
    "button1.pack()\n",
    "# button2 = tk.Button(root, text=\"Record Video\", command=record_video)\n",
    "# button2.pack(side=\"bottom\")\n",
    "# button3 = tk.Button(root, text=\"Record Video\", command=predict(file_path))\n",
    "# button3.pack(side=\"bottom\")\n",
    "button_start = tk.Button(root, text=\"Start Recording\", command=start_recording)\n",
    "button_start.place(x=10, y=260)\n",
    "#button_pred=tk.Button(root, text=\"Predict\", command=inputProcessing)\n",
    "#button_pred.pack()\n",
    "#button_start.pack()\n",
    "# button_stop = tk.Button(root, text=\"Stop Recording\", command=stop_recording)\n",
    "# button_stop.pack(side=\"left\")\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28865167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdb220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
