{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eed1d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization\n",
    "from keras import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "directory = r\"D:\\isl_projects\\datasets\"  # replace with your directory path\n",
    "\n",
    "files = os.listdir(directory)\n",
    "file_list = []\n",
    "\n",
    "for file in files:\n",
    "    file_list.append(file)\n",
    "\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1fd8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = file_list\n",
    "hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=2,\n",
    "                                 min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "sequenceLength = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22a116de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCoordinates(coords):\n",
    "\n",
    "    baseX = 0\n",
    "    baseY = 0\n",
    "\n",
    "    for i, val in enumerate(coords):\n",
    "        if i == 0:\n",
    "            baseX = val[0]\n",
    "            baseY = val[1]\n",
    "\n",
    "        coords[i][0] = coords[i][0] - baseX\n",
    "        coords[i][1] = coords[i][1] - baseY\n",
    "\n",
    "    coords = list(itertools.chain.from_iterable(coords))\n",
    "\n",
    "    maxVal = max(list(map(abs, coords)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / maxVal\n",
    "\n",
    "    coords = list(map(normalize_, coords))\n",
    "\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a10b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletonExtraction(path):\n",
    "\n",
    "    left = []\n",
    "    right = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "\n",
    "        if (success == False):\n",
    "\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(imgRGB)\n",
    "\n",
    "        hLeft = None\n",
    "        hRight = None\n",
    "\n",
    "        if (results.multi_hand_landmarks):\n",
    "            for idx, handLms in enumerate(results.multi_hand_landmarks):\n",
    "\n",
    "                hand = []\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y*h)\n",
    "                    hand.append([cx, cy])\n",
    "\n",
    "                label = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "                if (label == 'Left'):\n",
    "                    hLeft = normalizeCoordinates(hand)\n",
    "                elif (label == 'Right'):\n",
    "                    hRight = normalizeCoordinates(hand)\n",
    "\n",
    "        if (hLeft != None):\n",
    "            left.append(hLeft)\n",
    "        if (hRight != None):\n",
    "            right.append(hRight)\n",
    "\n",
    "    countLeft = len(left)\n",
    "    countRight = len(right)\n",
    "    windowLeft = max(countLeft/sequenceLength, 1)\n",
    "    windowRight = max(countRight/sequenceLength, 1)\n",
    "\n",
    "    finalFeatures = []\n",
    "\n",
    "    if countLeft < sequenceLength or countRight < sequenceLength:\n",
    "        return []\n",
    "\n",
    "    for i in range(0, sequenceLength):\n",
    "\n",
    "        finalFeatures.append(\n",
    "            left[int(i * windowLeft)] + right[int(i * windowRight)])\n",
    "\n",
    "    return np.asarray(finalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0ec2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputProcessing():\n",
    "    features = np.asarray([skeletonExtraction(select_video_file_name)])\n",
    "    jsonFile = open('final_model.json', 'r')\n",
    "    loadedModel = jsonFile.read()\n",
    "    loadedModel = keras.models.model_from_json(loadedModel)\n",
    "    loadedModel.load_weights('final_weights.h5')\n",
    "    loadedModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    output = loadedModel.predict(features)\n",
    "    label = classList[np.argmax(output)]\n",
    "    text_box.insert(tk.END, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c44f0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file_path):\n",
    "    jsonFile = open('my.json', 'r')\n",
    "    loadedModel = jsonFile.read()\n",
    "    loadedModel = keras.models.model_from_json(loadedModel)\n",
    "    loadedModel.load_weights('my.h5')\n",
    "    loadedModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    features = inputProcessing(select_video_file_name)\n",
    "    output = loadedModel.predict(features)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13994c5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 779ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import time\n",
    "# from model import predict\n",
    "#os.chdir(\"/home/vivek/college/capstone/gui\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"India Sign language Detector\")\n",
    "#root.iconbitmap(\"C:/Users/91790/Desktop/isl.png\")\n",
    "root.geometry(\"1920x1080\")\n",
    "root.configure(bg=\"#383838\")\n",
    "\n",
    "word_is=\"\"\n",
    "# root.configure(bg=\"yellow\")\n",
    "file_path = ''\n",
    "\n",
    "frame = tk.Frame(height=480, width=640,bg=\"#383838\")\n",
    "frame.place(x=10, y=30)\n",
    "lmain = tk.Label(frame)\n",
    "lmain.place(x=0, y=0)\n",
    "\n",
    "\n",
    "filename = str(time.time())+'video.avi'\n",
    "frames_per_second = 30.0\n",
    "res = '480p'\n",
    "\n",
    "# Set resolution for the video capture\n",
    "# Function adapted from https://kirr.co/0l6qmh\n",
    "\n",
    "\n",
    "def change_res(cap, width, height):\n",
    "    cap.set(3, width)\n",
    "    cap.set(4, height)\n",
    "\n",
    "\n",
    "# Standard Video Dimensions Sizes\n",
    "STD_DIMENSIONS = {\n",
    "    \"480p\": (640, 480),\n",
    "    \"720p\": (1280, 720),\n",
    "    \"1080p\": (1920, 1080),\n",
    "    \"4k\": (3840, 2160),\n",
    "}\n",
    "\n",
    "\n",
    "# grab resolution dimensions and set video capture to it.\n",
    "def get_dims(cap, res='1080p'):\n",
    "    width, height = STD_DIMENSIONS[\"480p\"]\n",
    "    if res in STD_DIMENSIONS:\n",
    "        width, height = STD_DIMENSIONS[res]\n",
    "    # change the current caputre device\n",
    "    # to the resulting resolution\n",
    "    change_res(cap, width, height)\n",
    "    return width, height\n",
    "\n",
    "\n",
    "# Video Encoding, might require additional installs\n",
    "# Types of Codes: http://www.fourcc.org/codecs.php\n",
    "VIDEO_TYPE = {\n",
    "    'avi': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    # 'mp4': cv2.VideoWriter_fourcc(*'H264'),\n",
    "    'mp4': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "}\n",
    "\n",
    "\n",
    "def get_video_type(filename):\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    if ext in VIDEO_TYPE:\n",
    "        return VIDEO_TYPE[ext]\n",
    "    return VIDEO_TYPE['avi']\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# out = cv2.VideoWriter(str(time.time())+'video.avi',\n",
    "#                       cv2.VideoWriter_fourcc(*'XVID'), 25, get_dims(cap, res))\n",
    "recording = False\n",
    "video_file_name = \"\"\n",
    "select_video_file_name=\"\"\n",
    "# Define a function to start recording\n",
    "\n",
    "\n",
    "def start_recording():\n",
    "    global recording,video_file_name\n",
    "    recording = True\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    video_file_name=str(time.time())+'video.avi'\n",
    "    out = cv2.VideoWriter(video_file_name,\n",
    "                          cv2.VideoWriter_fourcc(*'XVID'), 30, get_dims(cap, res))\n",
    "    button_start.config(text=\"Stop Recording\",\n",
    "                        command=lambda: stop_recording(cap, out))\n",
    "    record_video(cap, out)\n",
    "    # stop_recording\n",
    "# Define a function to stop recording\n",
    "\n",
    "\n",
    "\n",
    "def stop_recording(cap, out):\n",
    "    global recording\n",
    "    recording = False\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    \n",
    "    button_start.config(text=\"Start Recording\", command=start_recording)\n",
    "# This function should call the Python program that records webcam video using OpenCV.\n",
    "\n",
    "\n",
    "def record_video(cap, out):\n",
    "    if recording:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = image\n",
    "            imgarr = Image.fromarray(img)\n",
    "            imgtk = ImageTk.PhotoImage(imgarr)\n",
    "            lmain.imgtk = imgtk\n",
    "            lmain.configure(image=imgtk)\n",
    "        out.write(frame)\n",
    "        lmain.after(10, lambda: record_video(cap, out))\n",
    "        \n",
    "    # cv2.waitKey(1000)\n",
    "\n",
    "\n",
    "def choose_file():\n",
    "    global select_video_file_name\n",
    "    select_video_file_name = filedialog.askopenfilename(initialdir=\".\", title=\"Select a Video File\",\n",
    "                                           filetypes=((\"Video files\", \"*.mp4;*.avi;*.mov;*.mkv\"),\n",
    "                                                      (\"all files\", \"*.*\")))\n",
    "    display_video(select_video_file_name)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def display_video(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "    h, w, channels = frame.shape\n",
    "    scale_factor = 0.25  # Reduce the size by 4x\n",
    "    h = int(h * scale_factor)\n",
    "    w = int(w * scale_factor)\n",
    "    video_canvas.config(width=w, height=h)\n",
    "    video_canvas.place(x=650,y=30)\n",
    "    while ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        img = Image.fromarray(frame)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        video_canvas.img_tk = img_tk\n",
    "        video_canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "        root.update()\n",
    "        time.sleep(0.01)\n",
    "        ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "video_canvas = tk.Canvas(root)\n",
    "\n",
    "button1 = tk.Button(root, text=\"select video\",command=choose_file,bg='#383838',fg='#ffffff')\n",
    "button1.place(x=650, y=10)\n",
    "\n",
    "button_start = tk.Button(root, text=\"Start Recording\", command=start_recording,bg='#383838',fg='#ffffff')\n",
    "button_start.place(x=10, y=10)\n",
    "\n",
    "button_pred=tk.Button(root, text=\"Predict\",command=inputProcessing,bg='#383838',fg='#ffffff')\n",
    "button_pred.place(x=650,y=260)\n",
    "\n",
    "text_box = tk.Text(root,height=2, width=14,bg=\"#141620\",fg='#ffffff')\n",
    "text_box.place(x=650,y=280)\n",
    "\n",
    "#text_box1 = tk.Text(root,height=2, width=14,bg=\"#141414\")\n",
    "#text_box1.place(x=650,y=500)\n",
    "\n",
    "#options = [\"telugu\", \"tamil\", \"hindi\"]\n",
    "#selected_option = tk.StringVar()\n",
    "\n",
    "#selected_option.set(options[0])\n",
    "\n",
    "#dropdown = tk.OptionMenu(root, selected_option, *options)\n",
    "#dropdown.place(x=650,y=380)\n",
    "\n",
    "#button = tk.Button(root, text=\"Display Selection\", command=lambda: translate(selected_option.get(),word_is))\n",
    "#button.place(x=650,y=450)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b524c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
